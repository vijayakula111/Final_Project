{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict default of creditcard payments\n",
    "\n",
    "Introduction\n",
    "This binary classification studies the case of customers default payments in Taiwan. We get to study different aspects of customers like Gender, Education, Marital Status, Age, Payment history, Credit taken, etc., to determine if they are going to default payment in the next month.\n",
    "\n",
    "It will be interesting to understand which factors will have an impact on duly making or missing payments.\n",
    "\n",
    "This dataset is downloaded from UCI Machine Learning and more information on the data and the variables are found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim\n",
    "This research is aimed to compares the predictive accuracy of probability of default among bellow different data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable. Hence we compare results from different models and choose the one with highest accuracy.\n",
    "\n",
    "kNN\n",
    "Logistic Regression\n",
    "Decision Tree\n",
    "Ensembles: Random Forest\n",
    "Support Vector Machines\n",
    "Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#settings\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "raw_data = pd.read_excel(\"default of credit card clients.xls\", header=1)\n",
    "\n",
    "#drop ID column and reset column names\n",
    "raw_data = raw_data.drop('ID', axis=1)\n",
    "raw_data.columns = ['LIMIT_BAL', 'SEX', 'EDUCATION', 'MARRIAGE', 'AGE', \n",
    "                    'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', \n",
    "                    'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', \n",
    "                    'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', \n",
    "                    'default payment next month']\n",
    "print(\"Shape of the data:\",raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains data on 30000 customers with 23 explanatory variables and 1 response variable. Brief information on these below.\n",
    "\n",
    "X1: Limit_Bal Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit.\n",
    "X2: Sex Gender (1 = male; 2 = female).\n",
    "X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
    "X4: Marriage Marital status (1 = married; 2 = single; 3 = others).\n",
    "X5: Age (year).\n",
    "X6 - X11: History of past payment. Past monthly payment records (from April to September, 2005) as follows:\n",
    "X6 = PAY_1 the repayment status in September, 2005;\n",
    "X7 = PAY_2 the repayment status in August, 2005; . . .;\n",
    "X11 = PAY_6 the repayment status in April, 2005. The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.\n",
    "X12-X17: Amount of bill statement (NT dollar).\n",
    "X12 = BILL_AMT1 amount of bill statement in September, 2005;\n",
    "X13 = BILL_AMT2 amount of bill statement in August, 2005; . . .;\n",
    "X17 = BILL_AMT6 amount of bill statement in April, 2005.\n",
    "X18-X23: Amount of previous payment (NT dollar).\n",
    "X18 = PAY_AMT1 amount paid in September, 2005;\n",
    "X19 = PAY_AMT2 amount paid in August, 2005; . . .;\n",
    "X23 = PAY_AMT6 amount paid in April, 2005.\n",
    "Y: default payment next month (Yes = 1, No = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration\n",
    "Check for null values\n",
    "Study distribution of the variables\n",
    "Study correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We don't have any null values which is good. Let's visualize distribution of below 4 variables as other variables are either simillar to these or categorical. Studying these will give us an overview.\n",
    "\n",
    "LIMIT_BAL, AGE, BILL_AMT1, PAY_AMT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distributions\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(12,12))\n",
    "\n",
    "ax1.boxplot(raw_data['LIMIT_BAL'])\n",
    "ax1.set_title('LIMIT_BAL')\n",
    "ax2.boxplot(raw_data['AGE'])\n",
    "ax2.set_title('AGE')\n",
    "ax3.boxplot(raw_data['BILL_AMT1'])\n",
    "ax3.set_title('BILL_AMT1')\n",
    "ax4.boxplot(raw_data['PAY_AMT1'])\n",
    "ax4.set_title('PAY_AMT1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are a good number of outliers in each of our variables visualized above. To reduce their affect we can use RobustScaler to scale the data. This method will still keep the outliers but their influence on the data would be minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#correlation heatmap\n",
    "sns.heatmap(raw_data.corr(), cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Few observations that we can make from above plot\n",
    "\n",
    "'Past payments' seems to be only variables that are moderately highly correlated with 'default payment'\n",
    "followed by past bill amounts.\n",
    "also we don't find higly correlated independent variables though we can see some positive relation between 'bill amount' and 'pay amount' columns as well as 'past payments' and 'bill amount'.\n",
    "Preprocessing - Feature selection, One-hot encoding & Scaling Data\n",
    "Split data into train and test sets\n",
    "Perform Model-Based (RandomForest) feature selection to find important featuers\n",
    "Subset data with selected featuers\n",
    "Convert categorical variables using one-hot encoding.\n",
    "Scale data using RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test\n",
    "feature_cols = list(raw_data.columns[raw_data.columns != 'default payment next month'])\n",
    "target_col = 'default payment next month'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_data[feature_cols], \n",
    "                                                    raw_data[target_col],\n",
    "                                                    random_state=2, train_size=0.8)\n",
    "\n",
    "print(\"Training set with 80% data for training and validation:\",X_train.shape)\n",
    "print(\"Value counts in Training target column\")\n",
    "print(y_train.value_counts(normalize=True)*100)\n",
    "print(\"Test set with 20% data for testing:\",X_test.shape)\n",
    "print(\"Value counts in Test target column\")\n",
    "print(y_test.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance\n",
    "feature_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-2)\n",
    "feature_model.fit(X_train, y_train)\n",
    "\n",
    "feature_imp_df = pd.DataFrame({'col': X_train.columns,'imp' : feature_model.feature_importances_})\n",
    "feature_imp_df = feature_imp_df.sort_values('imp', ascending=False)\n",
    "feature_imp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table show the importance of each feature sorted descendingly. We can see the most significant factor in predicting default of next month payment is previous months payment status. Surprisingly, AGE made it to second in the list which is interesting. But intuitively the next important features are LIMIT_BAL, BILL_AMT1, BILL_AMT2 and PAY_AMT1. The feature importance given by the model makes logical sense as the features we just described are in general the deciding factors in the ability of one making a payment.\n",
    "\n",
    "Based on this, we shall choose the those features with value greater than 0.04. So, we have reduced number of features from 23 to 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#subset train and test sets\n",
    "new_features = list(feature_imp_df[feature_imp_df['imp']>0.04]['col'])\n",
    "\n",
    "X_train_new = X_train[new_features]\n",
    "X_test_new = X_test[new_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Of the new features we have 2 categorical variables and rest are numerical. Let's do dummy coding for those features and scale rest of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "categorical_vars = ['PAY_1', 'PAY_2']\n",
    "X_train_dummy = pd.get_dummies(X_train_new[categorical_vars], columns=categorical_vars, drop_first=True)\n",
    "X_test_dummy = pd.get_dummies(X_test_new[categorical_vars], columns=categorical_vars, drop_first=True)\n",
    "\n",
    "print(X_train_dummy.shape)\n",
    "print(X_test_dummy.shape)\n",
    "\n",
    "#drop original columns\n",
    "X_train_new = X_train_new.drop(categorical_vars, axis=1)\n",
    "X_test_new = X_test_new.drop(categorical_vars, axis=1)\n",
    "#data_transformed = pd.concat([data_dummies, data_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we have different number of columns is that there is only one record with value \"8\" in the column PAY_2. It will either fall in test or train randomly, train in our case. So let's add an additional column to test which says PAY_2_8 filling it with all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dummy['PAY_2_8'] = 0\n",
    "\n",
    "#convert dummy dataframes to numpy\n",
    "X_train_dummy = X_train_dummy.to_numpy()\n",
    "X_test_dummy = X_test_dummy.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#scale continuous data using RobustScaler\n",
    "continuous_vars = ['AGE', 'BILL_AMT1', 'LIMIT_BAL', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT6', 'BILL_AMT4',\n",
    "                   'BILL_AMT5', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT6', 'PAY_AMT3', 'PAY_AMT5', 'PAY_AMT4']\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train_new[continuous_vars])\n",
    "X_train_scaled = scaler.transform(X_train_new[continuous_vars])\n",
    "X_test_scaled = scaler.transform(X_test_new[continuous_vars])\n",
    "\n",
    "#combine scaled and dummy sets\n",
    "X_train_complete = np.concatenate((X_train_scaled, X_train_dummy), axis=1)\n",
    "X_test_complete = np.concatenate((X_test_scaled, X_test_dummy), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We now have our data ready for model training.\n",
    "\n",
    "Model buildingÂ¶\n",
    "Train and test different supervised machine learning models.\n",
    "kNN, Logistic Regression, Decision Tree, RandomForest, SVM, ANN\n",
    "Model evaluation, improvement and comparison.\n",
    "Use grid search in combination with cross validation to find best performing hyperparameters\n",
    "User those parameters to test set to find how well the model is generalized.\n",
    "Compare different models to choose the best performing one.\n",
    "We shall also use n_jobs parameter to take advantage of parellel processing and run models faster.\n",
    "Scoring Metric\n",
    "\n",
    "Since we are dealing with imbalanced data (78% negatives and 22% positives) Accuracy is no longer a good measure of performance for different models because if we simply predict all examples to belong to the negative class, we achieve 78% accuracy. So let's choos ROC curve as our metric for training our models.\n",
    "\n",
    "Note: The AUC value lies between 0.5 to 1 where 0.5 denotes a bad classifer and 1 denotes an perfect classifier. AUC values of .70 and higher would be considered strong effects.\n",
    "\n",
    "Class Weights\n",
    "\n",
    "We shall also use class_weights parameter in applicable models to make up for the imbalance in our data. The weights we use are class_weights = {0:1, 1:3.5} in proportion to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class weights\n",
    "class_weights = {0:1, 1:3.5}\n",
    "\n",
    "# function to fit model, find best parameters using grid search and cv and print results\n",
    "def learning_model(model, parameters, train_x, train_y, test_x, test_y, score_metric='roc_auc'):\n",
    "    #fit model and find best performing parameters\n",
    "    kf = KFold(10, shuffle=True, random_state=1)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=parameters, scoring = score_metric, cv=kf, n_jobs=-1)\n",
    "    grid_search.fit(train_x, train_y)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    train_score = grid_search.best_score_\n",
    "    test_score = grid_search.score(test_x, test_y)\n",
    "    predictions = grid_search.predict(test_x)\n",
    "    \n",
    "    return best_params, train_score, test_score, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. k-NN\n",
    "hyperparameter: \"n_neighbors\" - Try different values for nearest neighbors\n",
    "class_weights: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameter, fit model and display resutls\n",
    "param_grid = {'n_neighbors': np.arange(5,11,1)}\n",
    "knn_best_params, knn_train_score, knn_test_score, knn_predictions = learning_model(KNeighborsClassifier(), param_grid, X_train_complete, y_train, X_test_complete, y_test)\n",
    "\n",
    "print(\"k-NN Best parameters: {}\".format(knn_best_params))\n",
    "print(\"k-NN cross-validation roc_auc score: {:.3f}\".format(knn_train_score))\n",
    "print(\"k-NN Test roc_auc score: {:.3f}\".format(knn_test_score))\n",
    "print(\"k-NN Confusion Matrix\")\n",
    "pd.crosstab(y_test, knn_predictions,rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Logistic Regression\n",
    "hyperparameter: \"C\" - trade-off parameter that determines the strength of the regularization\n",
    "set solver: 'lbfgs' and max_iter:1000\n",
    "class_weights: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameter, fit model and display resutls\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "lr_best_params, lr_train_score, lr_test_score, lr_predictions = learning_model(LogisticRegression(solver='lbfgs', max_iter=1000, class_weight=class_weights), param_grid, X_train_complete, y_train, X_test_complete, y_test)\n",
    "\n",
    "print(\"LogReg Best parameters: {}\".format(lr_best_params))\n",
    "print(\"LogReg cross-validation roc_auc score: {:.3f}\".format(lr_train_score))\n",
    "print(\"LogReg Test roc_auc score: {:.3f}\".format(lr_test_score))\n",
    "print(\"LogReg Confusion Matrix\")\n",
    "pd.crosstab(y_test, lr_predictions,rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Decision Tree\n",
    "hyperparameter: \"max_depth\" - we shall restrict overfit using this parameter\n",
    "Since this is a tree based model we can simply use unscaled and unencoded sets.\n",
    "class_weights: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set hyperparameter, fit model and display resutls\n",
    "param_grid = {'max_depth': np.arange(4,11,1)}\n",
    "dt_best_params, dt_train_score, dt_test_score, dt_predictions = learning_model(DecisionTreeClassifier(random_state=1, class_weight=class_weights), param_grid, X_train_new, y_train, X_test_new, y_test)\n",
    "\n",
    "print(\"DecisionTree Best parameters: {}\".format(dt_best_params))\n",
    "print(\"DecisionTree cross-validation roc_auc score: {:.3f}\".format(dt_train_score))\n",
    "print(\"DecisionTree Test roc_auc score: {:.3f}\".format(dt_test_score))\n",
    "print(\"DecisionTree Confusion Matrix\")\n",
    "pd.crosstab(y_test, dt_predictions,rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. Ensembles - Random Forest\n",
    "hyperparameters\n",
    "\"max_depth\" - we shall restrict overfit using this parameter\n",
    "\"n_estimators\" - The number of trees in the forest.\n",
    "Since this is a tree based model we can again use unscaled and unencoded sets.\n",
    "class_weights: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#set hyperparameter, fit model and display resutls\n",
    "param_grid = {'max_depth': np.arange(4,11,1),\n",
    "              'n_estimators': [50, 100, 150, 200]}\n",
    "rf_best_params, rf_train_score, rf_test_score, rf_predictions = learning_model(RandomForestClassifier(random_state=1, class_weight=class_weights), param_grid, X_train_new, y_train, X_test_new, y_test)\n",
    "\n",
    "print(\"RandomForest Best parameters: {}\".format(rf_best_params))\n",
    "print(\"RandomForest cross-validation roc_auc score: {:.3f}\".format(rf_train_score))\n",
    "print(\"RandomForest Test roc_auc score: {:.3f}\".format(rf_test_score))\n",
    "print(\"RandomForest Confusion Matrix\")\n",
    "pd.crosstab(y_test, rf_predictions,rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. Support Vector Machines\n",
    "hyperparameters\n",
    "\"C\" - parameter that tunes the influence of each datapoint on decision boundary\n",
    "\"gamma\" - parameter that tunes how many support vectors are considered\n",
    "class_weights: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameter, fit model and display resutls\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "svc_best_params, svc_train_score, svc_test_score, svc_predictions = learning_model(SVC(class_weight=class_weights), param_grid, X_train_complete, y_train, X_test_complete, y_test)\n",
    "\n",
    "print(\"SVC Best parameters: {}\".format(svc_best_params))\n",
    "print(\"SVC cross-validation roc_auc score: {:.3f}\".format(svc_train_score))\n",
    "print(\"SVC Test roc_auc score: {:.3f}\".format(svc_test_score))\n",
    "print(\"SVC Confusion Matrix\")\n",
    "pd.crosstab(y_test, svc_predictions,rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6. Artificial Neural Network\n",
    "hyperparameters\n",
    "\"hidden_layer_sizes\" - parameter to tune number of hidden layers and number of nodes in each layer.\n",
    "\"alpha\" - parameter (l2 regularization) to shrink the weights towards zero.\n",
    "class_weights: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set hyperparameter, fit model and display resutls\n",
    "param_grid = {'hidden_layer_sizes': [[10],[100],[200],[10,10],[100,100]],\n",
    "              'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0]}\n",
    "nn_best_params, nn_train_score, nn_test_score, nn_predictions = learning_model(MLPClassifier(max_iter=1000, solver='lbfgs', random_state=0), param_grid, X_train_complete, y_train, X_test_complete, y_test)\n",
    "\n",
    "print(\"NeuralNetwork Best parameters: {}\".format(nn_best_params))\n",
    "print(\"NeuralNetwork cross-validation roc_auc score: {:.3f}\".format(nn_train_score))\n",
    "print(\"NeuralNetwork Test roc_auc score: {:.3f}\".format(nn_test_score))\n",
    "print(\"NeuralNetwork Confusion Matrix\")\n",
    "pd.crosstab(y_test, nn_predictions,rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model Evaluation\n",
    "We have trained 6 different models and the best ROC AUC score we achieve is 78.1% for Neural Network model and closely followed by LogReg 76.3% and SVM 76%.\n",
    "\n",
    "As we are dealing with imbalanced data, its important to look into False positives (where next month was not default and we predicted as default) and False negatives (where next month was default and we predicted as not default).\n",
    "\n",
    "Since we are viewing this problem from financial institution's perspective who are trying to find out defaulter's, we need to focus on Recall (True Positive Rate/Sensitivity) and Precision (Positive Predictive Value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate recall\n",
    "recall_knn = recall_score(y_test, knn_predictions)\n",
    "recall_lr = recall_score(y_test, lr_predictions)\n",
    "recall_dt = recall_score(y_test, dt_predictions)\n",
    "recall_rf = recall_score(y_test, rf_predictions)\n",
    "recall_svc = recall_score(y_test, svc_predictions)\n",
    "recall_nn = recall_score(y_test, nn_predictions)\n",
    "\n",
    "#calculate precision\n",
    "precision_knn = precision_score(y_test, knn_predictions)\n",
    "precision_lr = precision_score(y_test, lr_predictions)\n",
    "precision_dt = precision_score(y_test, dt_predictions)\n",
    "precision_rf = precision_score(y_test, rf_predictions)\n",
    "precision_svc = precision_score(y_test, svc_predictions)\n",
    "precision_nn = precision_score(y_test, nn_predictions)\n",
    "\n",
    "# comparison table\n",
    "model_comparison = pd.DataFrame({'Model':['k-NN', 'LogReg', 'DecisionTree', 'RandomForest', 'SVM', 'ANN'],\n",
    "                                 'roc_auc':[knn_test_score, lr_test_score, dt_test_score, rf_test_score, svc_test_score, nn_test_score],\n",
    "                                 'Recall/TPR':[recall_knn, recall_lr, recall_dt, recall_rf, recall_svc, recall_nn],\n",
    "                                 'Precision/PPV': [precision_knn, precision_lr, precision_dt, precision_rf, precision_svc, precision_nn]})\n",
    "\n",
    "model_comparison = model_comparison.set_index('Model')\n",
    "model_comparison.sort_values('roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "The best performing model for our problem in Neural Networks with an ROC AUC score of 78.1%, Recall of 37.2% and Precision of 67.4%. Given the imbalance in the data the model may not detect the class well but when it does it is highly trustable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
